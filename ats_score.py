# -*- coding: utf-8 -*-
"""ats_score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/rehaan7711/ats_score/blob/main/ats_score.ipynb
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('Resume.csv')

from google.colab import drive
drive.mount('/content/drive')

df.head(10)

df['Resume'][0]

df['Category'].value_counts()

# Data Cleanning

"""
1. urls
2. hashtags
3. mentions
4. special letters
5. punctuations

"""

import re

def cleanResume(txt):
  cleantext = re.sub('http\S+\s'," ",txt)
  cleantext = re.sub('#\S+\s'," ",cleantext)
  cleantext = re.sub('RT|cc'," ",cleantext)
  cleantext = re.sub('@\S+\s'," ",cleantext)
  cleantext = re.sub('[%s]'% re.escape("""@!#$%^&*()_+=-{}[]\|:;,<>.?/"""),' ',cleantext)
  return cleantext

df['Resume'] = df['Resume'].apply(lambda x:cleanResume(x))

print(df['Resume'][0])

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Category'] = le.fit_transform(df['Category'])

df.head()

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')
tfidf.fit(df['Resume'])

requiredtext = tfidf.transform(df['Resume'])

print(requiredtext)

from sklearn.model_selection import train_test_split

x_train , x_test , y_train , y_test= train_test_split(requiredtext,df['Category'],test_size=0.2,random_state=87)

from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier()
model.fit(x_train , y_train)

model.predict(x_test)

from sklearn.metrics import classification_report
y_pred = model.predict(x_test)
print(classification_report(y_pred,y_test))

# prediction part

import pickle

pickle.dump(tfidf,open('tfidf.pkl','wb'))
pickle.dump(model,open('kn.pkl','wb'))

resume = """

"""

x = pickle.load(open('model.pkl','rb'))
cleaned_resume = cleanResume(resume)

input_features = tfidf.transform([cleaned_resume])

prediction_id = x.predict(input_features)[0]
category_mapping = {
            15: "Java Developer",
            23: "Testing",
            8: "DevOps Engineer",
            20: "Python Developer",
            24: "Web Designing",
            12: "HR",
            13: "Hadoop",
            3: "Blockchain",
            10: "ETL Developer",
            18: "Operations Manager",
            6: "Data Science",
            22: "Sales",
            16: "Mechanical Engineer",
            1: "Arts",
            7: "Database",
            11: "Electrical Engineering",
            14: "Health and fitness",
            19: "PMO",
            4: "Business Analyst",
            9: "DotNet Developer",
            2: "Automation Testing",
            17: "Network Security Engineer",
            21: "SAP Developer",
            5: "Civil Engineer",
            0: "Advocate",
}

category_name = category_mapping.get(prediction_id)
print("The resume belongs to the category of",category_name)

# prompt: can you please give me streamlit code for entire project what i did above

import streamlit as st
import pickle
import re
from sklearn.feature_extraction.text import TfidfVectorizer

# Load the saved model and TF-IDF vectorizer
tfidf = pickle.load(open('tfidf.pkl', 'rb'))
model = pickle.load(open('kn.pkl', 'rb'))

# Define the category mapping
category_mapping = {
    15: "Java Developer",
    23: "Testing",
    8: "DevOps Engineer",
    20: "Python Developer",
    24: "Web Designing",
    12: "HR",
    13: "Hadoop",
    3: "Blockchain",
    10: "ETL Developer",
    18: "Operations Manager",
    6: "Data Science",
    22: "Sales",
    16: "Mechanical Engineer",
    1: "Arts",
    7: "Database",
    11: "Electrical Engineering",
    14: "Health and fitness",
    19: "PMO",
    4: "Business Analyst",
    9: "DotNet Developer",
    2: "Automation Testing",
    17: "Network Security Engineer",
    21: "SAP Developer",
    5: "Civil Engineer",
    0: "Advocate",
}

# Function to clean the resume text
def cleanResume(txt):
    cleantext = re.sub('http\S+\s', " ", txt)
    cleantext = re.sub('#\S+\s', " ", cleantext)
    cleantext = re.sub('RT|cc', " ", cleantext)
    cleantext = re.sub('@\S+\s', " ", cleantext)
    cleantext = re.sub('[%s]' % re.escape("""@!#$%^&*()_+=-{}[]\|:;,<>.?/"""), ' ', cleantext)
    return cleantext

# Streamlit app
st.title("Resume Category Prediction")

# Input resume text
resume_text = st.text_area("Enter the resume text:", height=200)


if st.button("Predict"):
    if resume_text:
        cleaned_resume = cleanResume(resume_text)
        input_features = tfidf.transform([cleaned_resume])
        prediction_id = model.predict(input_features)[0]
        category_name = category_mapping.get(prediction_id)
        st.write(f"The predicted category for the resume is: **{category_name}**")
    else:
        st.warning("Please enter resume text.")

# prompt: how should i run the code on streamlit interface please let me know

import streamlit as st
import pickle
import re

# Load the saved model and TF-IDF vectorizer
tfidf = pickle.load(open('tfidf.pkl', 'rb'))
model = pickle.load(open('kn.pkl', 'rb'))

# Define the category mapping
category_mapping = {
    15: "Java Developer",
    23: "Testing",
    8: "DevOps Engineer",
    20: "Python Developer",
    24: "Web Designing",
    12: "HR",
    13: "Hadoop",
    3: "Blockchain",
    10: "ETL Developer",
    18: "Operations Manager",
    6: "Data Science",
    22: "Sales",
    16: "Mechanical Engineer",
    1: "Arts",
    7: "Database",
    11: "Electrical Engineering",
    14: "Health and fitness",
    19: "PMO",
    4: "Business Analyst",
    9: "DotNet Developer",
    2: "Automation Testing",
    17: "Network Security Engineer",
    21: "SAP Developer",
    5: "Civil Engineer",
    0: "Advocate",
}

# Function to clean the resume text
def cleanResume(txt):
    cleantext = re.sub('http\S+\s', " ", txt)
    cleantext = re.sub('#\S+\s', " ", cleantext)
    cleantext = re.sub('RT|cc', " ", cleantext)
    cleantext = re.sub('@\S+\s', " ", cleantext)
    cleantext = re.sub('[%s]' % re.escape("""@!#$%^&*()_+=-{}[]\|:;,<>.?/"""), ' ', cleantext)
    return cleantext

# Streamlit app
st.title("Resume Category Prediction")

# Input resume text
resume_text = st.text_area("Enter the resume text:", height=200)


if st.button("Predict"):
    if resume_text:
        cleaned_resume = cleanResume(resume_text)
        input_features = tfidf.transform([cleaned_resume])
        prediction_id = model.predict(input_features)[0]
        category_name = category_mapping.get(prediction_id)
        st.write(f"The predicted category for the resume is: **{category_name}**")
    else:
        st.warning("Please enter resume text.")

# prompt: can you take inut as a pdf file of resume and predict output on streamlit

import streamlit as st
import pickle
import re

# Load the saved model and TF-IDF vectorizer
try:
    tfidf = pickle.load(open('tfidf.pkl', 'rb'))
    model = pickle.load(open('kn.pkl', 'rb'))
except FileNotFoundError:
    st.error("Model files (tfidf.pkl and kn.pkl) not found. Please upload them.")
    st.stop()

# Define the category mapping
category_mapping = {
    15: "Java Developer",
    23: "Testing",
    8: "DevOps Engineer",
    20: "Python Developer",
    24: "Web Designing",
    12: "HR",
    13: "Hadoop",
    3: "Blockchain",
    10: "ETL Developer",
    18: "Operations Manager",
    6: "Data Science",
    22: "Sales",
    16: "Mechanical Engineer",
    1: "Arts",
    7: "Database",
    11: "Electrical Engineering",
    14: "Health and fitness",
    19: "PMO",
    4: "Business Analyst",
    9: "DotNet Developer",
    2: "Automation Testing",
    17: "Network Security Engineer",
    21: "SAP Developer",
    5: "Civil Engineer",
    0: "Advocate",
}

# Function to clean the resume text
def cleanResume(txt):
    cleantext = re.sub('http\S+\s', " ", txt)
    cleantext = re.sub('#\S+\s', " ", cleantext)
    cleantext = re.sub('RT|cc', " ", cleantext)
    cleantext = re.sub('@\S+\s', " ", cleantext)
    cleantext = re.sub('[%s]' % re.escape("""@!#$%^&*()_+=-{}[]\|:;,<>.?/"""), ' ', cleantext)
    return cleantext

# Streamlit app
st.title("Resume Category Prediction")

uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")

if uploaded_file is not None:
    try:
        from PyPDF2 import PdfReader
        reader = PdfReader(uploaded_file)
        resume_text = ""
        for page in reader.pages:
          resume_text += page.extract_text()

        cleaned_resume = cleanResume(resume_text)
        input_features = tfidf.transform([cleaned_resume])
        prediction_id = model.predict(input_features)[0]
        category_name = category_mapping.get(prediction_id)
        st.write(f"The predicted category for the resume is: **{category_name}**")

    except ImportError:
        st.error("PyPDF2 library not found. Please install it using `pip install PyPDF2`.")
    except Exception as e:
        st.error(f"An error occurred: {e}")

else:
    st.info("Please upload a PDF file.")